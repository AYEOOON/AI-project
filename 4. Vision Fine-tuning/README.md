# 🍀FINE-TUNING & TRANSFER LEARNING
![Untitled](https://github.com/AYEOOON/AI-project/assets/101050134/6e955d29-aeb7-4a59-b3c4-2c493d3af7fd)


### ☝FINE-TUNING
##### 1. 모델 전체를 학습하는 경우
- 크기가 크고 유사성이 작은 데이터셋일 때
- 데이터셋 크기가 크므로, 모델을 다시 처음부터 내가 원하는대로 다시 학습 가능

##### 2. 일부만 학습시키는 경우
- Convolutional base의 일부분은 고정시킨 상태로, 나머지 계층과 분류기를 새로 학습
- 크기가 크고 유사성도 높은 데이터셋
- 만약 데이터셋이 작고 모델의 파라미터가 많다면, 과적합이 발생할 수 있다.
- 데이터셋이 크고 모델이 작아 파라미터가 적다면, 과적합을 걱정할 필요가 없다.

##### 3. 학습 과정 없이 사용하는 경우
- Convolutional base는 고정시키고, 분류기만 새로 학습
- 이 경우는 극단적인 상황일 때 생각할 수 있는 경우
- convolutional base는 건들지 않고 그대로 두면서 **특징 추출 메커니즘으로써 활용**하고, **분류기만 재학습**시키는 방법
- 컴퓨팅 연산 능력이 부족하거나 데이터셋이 너무 작을 때, 내가 풀고자 하는 문제가 사전학습 모델이 이미 학습한 데이터셋과 매우 비슷할 때 사용


### ✌TRANSFER LEARNING
- 딥러닝을 특징추출기로만 사용하고 그렇게 추출한 특징를 가지고 다른 모델을 학습하는 것
- 일반적으로 VGG, ResNet, googleNet 등 이미 사전에 학습이 완료된 모델을 가지고 우리가 원하는 학습에 미세조정 즉, 작은 변화를 이용하여 학습시키는 방법
- 신경망의 이러한 재학습 과정을 **Fine-tuning** 이라고 부름
- Transfer learning의 방법 중 하나가 fine tuning이다.

------------------------------------------------
# TorchVision Object Detection Finetuning Tutorial
본 튜토리얼에서는 Penn-Fudan Database for Pedestrian Detection and Segmentation 데이터셋으로 미리 학습된 Mask R-CNN 모델을 미세조정 해 볼 것입니다. 

이 데이터셋에는 보행자 인스턴스(이미지 내에서 사람의 위치 좌표와 픽셀 단위의 사람 여부를 구분한 정보를 포함합니다.) 345명이 있는 170개의 이미지가 포함되어 있으며, 우리는 이 이미지를 사용하여 사용자 정의 데이터셋에 인스턴스 분할(Instance Segmentation) 모델을 학습하기 위해 torchvision의 새로운 기능을 사용하는 방법을 설명합니다. 

##### 1. 데이터셋 정의하기
##### 2. 모델 정의하기
1- 미리 학습된 모델로부터 미세조정

2- 다른 백복을 추가하도록 모델을 수정하기
##### 3. PennFudan 데이터셋을 위한 인스턴스 분할 모델
##### 4. 모든 것을 하나로 합치기

--------------------------------------------------
# TRANSFER LEARNING FOR COMPUTER VISION TUTORIAL
이 튜토리얼에서는 전이학습(Transfer Learning)을 이용하여 이미지 분류를 위한 합성곱 신경망을 어떻게 학습시키는지 배워보겠습니다.

###### 전이학습
실제로 충분한 크기의 데이터셋을 갖추기는 상대적으로 드물기 때문에, (무작위 초기화를 통해) 맨 처음부터 합성곱 신경망(Convolutional Network) 전체를 학습하는 사람은 매우 적습니다. 대신, 매우 큰 데이터셋(예. 100가지 분류에 대해 120만개의 이미지가 포함된 ImageNet)에서 합성곱 신경망(ConvNet)을 미리 학습한 후, 이 합성곱 신경망을 관심있는 작업 을 위한 초기 설정 또는 고정된 특징 추출기(fixed feature extractor)로 사용합니다.

이러한 전이학습 시나리오의 주요한 2가지는 다음과 같습니다:

- **합성곱 신경망의 미세조정(finetuning)**: 무작위 초기화 대신, 신경망을 ImageNet 1000 데이터셋 등으로 미리 학습한 신경망으로 초기화합니다. 학습의 나머지 과정들은 평상시와 같습니다.

- **고정된 특징 추출기로써의 합성곱 신경망**: 여기서는 마지막에 완전히 연결 된 계층을 제외한 모든 신경망의 가중치를 고정합니다. 이 마지막의 완전히 연결된 계층은 새로운 무작위의 가중치를 갖는 계층으로 대체되어 이 계층만 학습합니다.

##### 1. 데이터셋 정의하기
##### 2. 모델 예측값 시각화하기
##### 3. 합성곱 신경망 미세조정(finetuning)
##### 4. 학습 및 평가하기
##### 5. 고정된 특징 추출기로써의 합성곱 신경망
##### 6. 학습 및 평가하기
